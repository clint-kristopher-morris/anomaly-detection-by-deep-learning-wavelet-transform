{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "def time2Mins(time_):\n",
    "    hr2min, mins = time_.split(':')\n",
    "    return (int(hr2min)*60)+int(mins)\n",
    "\n",
    "def date2Mins(date):\n",
    "    date_format = \"%m/%d/%Y\"\n",
    "    d0 = datetime.strptime(str(date), date_format)\n",
    "    d1 = datetime.strptime('07/31/2019', date_format)\n",
    "    delta = d0 - d1\n",
    "    return int((delta.days)*24*60)\n",
    "\n",
    "\n",
    "df = dd.read_csv('./data/csv/2769/2769_*.csv')\n",
    "# df can fit in mem so use persist\n",
    "df = df.persist()\n",
    "df.datestamp = df.datestamp.map(lambda x: date2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "df.timestamp = df.timestamp.map(lambda x: time2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "df['time_anchor'] = df.datestamp + df.timestamp\n",
    "\n",
    "lane_list = list(df['lane_type'].unique().compute())\n",
    "lane_df_dict = {}\n",
    "for idx, lane in enumerate(lane_list):\n",
    "    lane_df_dict[idx] = df.loc[lambda df: df['lane_type'] == lane]\n",
    "    lane_df_dict[idx].to_csv(f'./data/2769_{lane}.csv', single_file = True)\n",
    "    \n",
    "end = time.time()\n",
    "f'the process took: {end-start}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# join 37 files into a single df\n",
    "df = dd.read_csv('./data/csv/2769/2769_*.csv')\n",
    "df = df.repartition(npartitions=4)\n",
    "# df can fit in mem so use persist\n",
    "df = df.persist()\n",
    "# map columns and create new column\n",
    "df.datestamp = df.datestamp.map(lambda x: date2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "df.timestamp = df.timestamp.map(lambda x: time2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "df['time_anchor'] = df.datestamp + df.timestamp\n",
    "df.visualize(filename='transpose.svg')\n",
    "\n",
    "\n",
    "\n",
    "print(df)\n",
    "# find the number of lanes of the road and split the data\n",
    "lane_list = list(df['lane_type'].unique())\n",
    "lane_df_dict = {}\n",
    "for lane in lane_list:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.loc[lambda df: df['lane_type'] == lane].to_csv(f'./data/2769_{lane}.csv', single_file = True)\n",
    "    \n",
    "end = time.time()\n",
    "f'the process took: {end-start}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# join 37 files into a single df\n",
    "df = dd.read_csv('./data/csv/2769/2769_*.csv')\n",
    "df.set_index('lane_type')\n",
    "# df.index = df.lane_type\n",
    "\n",
    "df = df.repartition(npartitions=4)\n",
    "\n",
    "df = df.map_partitions(lambda x:  x.sort_index())\n",
    "# df can fit in mem so use persist\n",
    "\n",
    "# df = df.persist()\n",
    "# map columns and create new column\n",
    "df.datestamp = df.datestamp.map(lambda x: date2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "df.timestamp = df.timestamp.map(lambda x: time2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "df['time_anchor'] = df.datestamp + df.timestamp\n",
    "\n",
    "df.to_csv('./data/*.csv')\n",
    "\n",
    "end = time.time()\n",
    "f'the process took: {end-start}'\n",
    "\n",
    "\n",
    "\n",
    "# df.visualize(filename='transpose.svg')\n",
    "# lane_list = list(df['lane_type'].unique())\n",
    "# ddf_selected = df.map_partitions(lambda x: x[x['lane_type'] == lane_list[0]], meta = df.dtypes)\n",
    "\n",
    "# print(df)\n",
    "# # find the number of lanes of the road and split the data\n",
    "\n",
    "# lane_df_dict = {}\n",
    "# for lane in lane_list:\n",
    "\n",
    "    \n",
    "#     df.loc[lambda df: .to_csv(f'./data/2769_{lane}.csv', single_file = True)\n",
    "    \n",
    "# end = time.time()\n",
    "# f'the process took: {end-start}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# join 37 files into a single df\n",
    "ddf = dd.read_csv('./data/csv/2769/2769_*.csv')\n",
    "ddf = ddf.repartition(npartitions=3)\n",
    "ddf = ddf.set_index('lane_type', sorted=True)\n",
    "ddf = ddf.map_partitions(lambda x:  x.sort_index())\n",
    "# map columns and create new column\n",
    "ddf.datestamp = ddf.datestamp.map(lambda x: date2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "ddf.timestamp = ddf.timestamp.map(lambda x: time2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "ddf = ddf.map_partitions(lambda df: df.assign(time_anchor=(df.datestamp + df.timestamp)))\n",
    "# df can fit in mem so use persist\n",
    "ddf = ddf.persist()\n",
    "end = time.time()\n",
    "print(f'1st process took: {end-start}')\n",
    "start = time.time()\n",
    "# df.to_parquet('./data/temp.parq',write_index=False)\n",
    "# df.to_feather('/data/testdf.feather')\n",
    "ddf.to_csv('./data/*.csv')\n",
    "end = time.time()\n",
    "print(f'2nd process took: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# join 37 files into a single df\n",
    "ddf = dd.read_csv('./data/csv/2769/2769_*.csv')\n",
    "ddf = ddf.repartition(npartitions=4)\n",
    "# ddf = ddf.set_index('lane_type', sorted=True)\n",
    "# ddf = ddf.map_partitions(lambda x:  x.sort_index())\n",
    "# map columns and create new column\n",
    "ddf.datestamp = ddf.datestamp.map(lambda x: date2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "ddf.timestamp = ddf.timestamp.map(lambda x: time2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "ddf = ddf.map_partitions(lambda df: df.assign(z=(df.datestamp + df.timestamp)))\n",
    "# df can fit in mem so use persist\n",
    "ddf = ddf.persist()\n",
    "end = time.time()\n",
    "print(f'1st process took: {end-start}')\n",
    "start = time.time()\n",
    "# df.to_parquet('./data/temp.parq',write_index=False)\n",
    "# df.to_feather('/data/testdf.feather')\n",
    "ddf.to_csv('./data/*.csv')\n",
    "# ddf.to_parquet('./data/iiii.csv', write_index=False)\n",
    "\n",
    "end = time.time()\n",
    "print(f'2nd process took: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "start = time.time()\n",
    "stations_dir = './data/batched/errored2'\n",
    "dfs = {}\n",
    "for station in os.listdir(stations_dir):\n",
    "    file_path = f'{stations_dir}/{station}'\n",
    "    # join 37 files into a single df\n",
    "    dfs[station] = dd.read_csv(f'{file_path}/*.csv')\n",
    "    dfs[station] = dfs[station].repartition(npartitions=4)\n",
    "    dfs[station] = dfs[station].set_index('lane_type', sorted=True)\n",
    "    dfs[station] = dfs[station].map_partitions(lambda x:  x.sort_index())\n",
    "    # map columns and create new column\n",
    "    dfs[station].datestamp = dfs[station].datestamp.map(lambda x: date2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "    dfs[station].timestamp = dfs[station].timestamp.map(lambda x: time2Mins(x), meta=pd.Series([], dtype=str, name='x'))\n",
    "    dfs[station]['time_anchor'] = dfs[station].datestamp + dfs[station].timestamp\n",
    "    # df can fit in mem so use persist\n",
    "    dfs[station] = dfs[station].persist()\n",
    "    end = time.time()\n",
    "    print(f'1st process took: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-outreach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-vegetable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-latex",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
